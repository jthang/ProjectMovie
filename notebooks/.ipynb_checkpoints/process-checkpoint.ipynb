{
 "metadata": {
  "name": "",
  "signature": "sha256:9bc6c1f7c90ab0db528cb624033a9ca5650f0fea76d164618058d01ea3c7e7de"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.cross_validation import KFold\n",
      "from sklearn.feature_extraction.text import CountVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# movies = pd.read_csv('../data/movies.dat', delimiter='\\t')\n",
      "df = pd.read_csv('../data/critics.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_xy(df, vectorizer=None):\n",
      "    if vectorizer is None:\n",
      "        vectorizer = CountVectorizer()\n",
      "    X = vectorizer.fit_transform(df.quote)\n",
      "    X = X.tocsc()\n",
      "    Y = (df.fresh == 'fresh').values.astype(np.int)\n",
      "    return X, Y\n",
      "\n",
      "def log_likelihood(clf, x, y):\n",
      "    prob = clf.predict_log_proba(x)\n",
      "    rotten = y == 0\n",
      "    fresh = ~rotten\n",
      "    return prob[rotten, 0].sum() + prob[fresh, 1].sum()\n",
      "\n",
      "def cv_score(clf, x, y, score_func):\n",
      "    result = 0\n",
      "    nfold = 5\n",
      "    for train, test in KFold(y.size, nfold):\n",
      "        clf.fit(x[train], y[train])\n",
      "        result += score_func(clf, x[test], y[test]) \n",
      "    return result / nfold\n",
      "\n",
      "alphas = [0, .1, 1, 5, 10, 50]\n",
      "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
      "\n",
      "best_alpha = None\n",
      "best_min_df = None\n",
      "max_loglike = -np.inf\n",
      "\n",
      "for alpha in alphas:\n",
      "    for min_df in min_dfs:         \n",
      "        vectorizer = CountVectorizer(min_df = min_df)       \n",
      "        X, Y = make_xy(df, vectorizer)\n",
      "        clf = MultinomialNB(alpha=alpha)\n",
      "        loglike = cv_score(clf, X, Y, log_likelihood)\n",
      "\n",
      "        if loglike > max_loglike:\n",
      "            max_loglike = loglike\n",
      "            best_alpha, best_min_df = alpha, min_df\n",
      "\n",
      "print best_alpha, best_min_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vectorizer = CountVectorizer(min_df=best_min_df)\n",
      "X, Y = make_xy(df, vectorizer)\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)\n",
      "\n",
      "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
      "\n",
      "print clf.score(xtrain, ytrain)\n",
      "print clf.score(xtest, ytest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, Y = make_xy(df, vectorizer)\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)\n",
      "\n",
      "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
      "\n",
      "new_review = ['this is a new review, movie was awesome']\n",
      "new_review = vectorizer.fit_transform(p)\n",
      "\n",
      "print df.quote[15]\n",
      "print(clf.predict(df.quote[10]))\n",
      "print(clf.predict(p))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_csv('../data/critics.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "X = vectorizer.fit_transform(df.quote)\n",
      "X = X.tocsc()\n",
      "Y = (df.fresh == 'fresh').values.astype(np.int)\n",
      "\n",
      "xtrain, xtest, ytrain, ytest = train_test_split(X, Y)\n",
      "\n",
      "clf = MultinomialNB().fit(xtrain, ytrain)\n",
      "\n",
      "new_review = ['this is a new review, movie was awesome']\n",
      "new_review = vectorizer.fit_transform(new_review)\n",
      "\n",
      "print df.quote[15]\n",
      "print(clf.predict(df.quote[10])) #predict existing quote in dataframe\n",
      "print(clf.predict(new_review)) #predict new review"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Technically, Toy Story is nearly flawless.\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "Cannot cast array data from dtype('float64') to dtype('S32') according to the rule 'safe'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-91-27a0698bbd1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquote\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#predict existing quote in dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_review\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#predict new review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;34m\"\"\"Calculate the posterior log probability of the samples X\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast2d_or_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         return (safe_sparse_dot(X, self.feature_log_prob_.T)\n\u001b[0m\u001b[1;32m    442\u001b[0m                 + self.class_log_prior_)\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: Cannot cast array data from dtype('float64') to dtype('S32') according to the rule 'safe'"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}